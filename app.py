import streamlit as st
import pandas as pd
import difflib
from io import BytesIO
import bibtexparser

# ---------------------- X·ª≠ l√Ω d·ªØ li·ªáu ƒë·∫ßu v√†o ------------------------

def clean_title(title):
    if pd.isnull(title):
        return ""
    return ''.join(e for e in title.lower().strip() if e.isalnum() or e.isspace())

def convert_isi_bibtex_to_scopus(df):
    converted = pd.DataFrame()
    converted["Title"] = df.get("title", "")
    converted["Authors"] = df.get("author", "")
    converted["Source title"] = df.get("journal", "")
    converted["Year"] = df.get("year", "")
    converted["DOI"] = df.get("doi", "")
    converted["Author Keywords"] = df.get("keywords", "")
    converted["Affiliations"] = df.get("institution", df.get("note", ""))
    converted["References"] = ""
    return converted

def merge_datasets(df1, df2):
    df1["title_clean"] = df1["Title"].apply(clean_title)
    df2["title_clean"] = df2["Title"].apply(clean_title)

    merged = pd.merge(df1, df2, on="DOI", how="outer", suffixes=('_isi', '_scopus'))

    no_doi_isi = df1[df1["DOI"].isnull()]
    no_doi_scopus = df2[df2["DOI"].isnull()]
    for _, row in no_doi_isi.iterrows():
        matches = difflib.get_close_matches(row["title_clean"], no_doi_scopus["title_clean"], n=1, cutoff=0.95)
        if matches:
            match_row = no_doi_scopus[no_doi_scopus["title_clean"] == matches[0]]
            if not match_row.empty:
                merged_row = pd.merge(row.to_frame().T, match_row, on="title_clean", how="inner")
                merged = pd.concat([merged, merged_row])

    merged.drop(columns=["title_clean"], inplace=True, errors="ignore")
    return merged

def convert_df_for_export(df):
    # ∆Øu ti√™n Scopus, thay th·∫ø n·∫øu thi·∫øu b·∫±ng ISI
    df["Title"] = df.get("Title_scopus", "").fillna(df.get("Title_isi", ""))
    df["Authors"] = df.get("Authors_scopus", "").fillna(df.get("Authors_isi", ""))
    df["Source title"] = df.get("Source title_scopus", "").fillna(df.get("Source title_isi", ""))
    df["Year"] = df.get("Year_scopus", "").fillna(df.get("Year_isi", ""))
    df["DOI"] = df.get("DOI", "")
    df["Author Keywords"] = df.get("Author Keywords_scopus", "").fillna(df.get("Author Keywords_isi", ""))
    df["Index Keywords"] = df.get("Index Keywords_scopus", "")
    df["Affiliations"] = df.get("Affiliations_scopus", "").fillna(df.get("Affiliations_isi", ""))
    df["References"] = df.get("References_scopus", "").fillna(df.get("References_isi", ""))

    export_df = df[[
        "Title", "Authors", "Source title", "Year", "DOI",
        "Author Keywords", "Index Keywords", "Affiliations", "References"
    ]]

    # ‚úÖ ƒê·∫£m b·∫£o t√™n c·ªôt chu·∫©n Scopus, tr√°nh l·ªói VOSviewer
    export_df.columns = [
        "Title", "Authors", "Source title", "Year", "DOI",
        "Author Keywords", "Index Keywords", "Affiliations", "References"
    ]

    buffer = BytesIO()
    export_df.to_csv(buffer, index=False)
    return buffer.getvalue()

# ---------------------- Giao di·ªán ng∆∞·ªùi d√πng ------------------------

st.set_page_config(page_title="Gh√©p d·ªØ li·ªáu ISI v√† Scopus", layout="wide")
st.title("üîó ·ª®ng d·ª•ng Gh√©p D·ªØ li·ªáu ISI & Scopus (chu·∫©n Scopus cho VOSviewer)")

file1 = st.file_uploader("üìÑ Ch·ªçn file ISI (.bib, .csv, .xlsx)", type=["bib", "csv", "xlsx"])
file2 = st.file_uploader("üìÑ Ch·ªçn file Scopus (.csv, .xlsx)", type=["csv", "xlsx"])

if file1 and file2:
    try:
        # X·ª≠ l√Ω ISI
        ext1 = file1.name.split(".")[-1].lower()
        if ext1 == "bib":
            bib_data = bibtexparser.load(file1)
            isi_raw_df = pd.DataFrame(bib_data.entries)
            isi_df = convert_isi_bibtex_to_scopus(isi_raw_df)
        elif ext1 == "csv":
            isi_raw_df = pd.read_csv(file1)
            isi_df = convert_isi_bibtex_to_scopus(isi_raw_df)
        elif ext1 == "xlsx":
            isi_raw_df = pd.read_excel(file1)
            isi_df = convert_isi_bibtex_to_scopus(isi_raw_df)
        else:
            st.error("‚ùå ƒê·ªãnh d·∫°ng file ISI kh√¥ng h·ª£p l·ªá.")
            st.stop()

        # X·ª≠ l√Ω Scopus
        ext2 = file2.name.split(".")[-1].lower()
        if ext2 == "csv":
            scopus_df = pd.read_csv(file2)
        elif ext2 == "xlsx":
            scopus_df = pd.read_excel(file2)
        else:
            st.error("‚ùå ƒê·ªãnh d·∫°ng file Scopus kh√¥ng h·ª£p l·ªá.")
            st.stop()

        scopus_df.columns = scopus_df.columns.str.strip()

        # C·∫£nh b√°o thi·∫øu c·ªôt
        required = ["Title", "Authors", "DOI"]
        warnings = []
        for col in required:
            if col not in isi_df.columns or isi_df[col].isnull().all():
                warnings.append(f"üìÅ ISI thi·∫øu ho·∫∑c tr·ªëng: `{col}`")
            if col not in scopus_df.columns or scopus_df[col].isnull().all():
                warnings.append(f"üìÅ Scopus thi·∫øu ho·∫∑c tr·ªëng: `{col}`")

        if warnings:
            st.warning("‚ö†Ô∏è M·ªôt s·ªë tr∆∞·ªùng d·ªØ li·ªáu b·ªã thi·∫øu:")
            for w in warnings:
                st.markdown(f"- {w}")

        with st.spinner("üîÑ ƒêang x·ª≠ l√Ω v√† gh√©p d·ªØ li·ªáu..."):
            merged_df = merge_datasets(isi_df, scopus_df)

        st.success("‚úÖ Gh√©p d·ªØ li·ªáu ho√†n t·∫•t!")
        st.dataframe(merged_df.head(50), use_container_width=True)

        # Ki·ªÉm tra s·ªë l∆∞·ª£ng t√°c gi·∫£
        all_authors = merged_df.get("Authors_scopus", "").fillna(merged_df.get("Authors_isi", "")).dropna()
        if all_authors.nunique() < 3:
            st.error("‚ùå D·ªØ li·ªáu c·∫ßn √≠t nh·∫•t 3 t√°c gi·∫£ kh√°c nhau ƒë·ªÉ d√πng v·ªõi VOSviewer.")
        else:
            csv = convert_df_for_export(merged_df)
            st.download_button("üì• T·∫£i xu·ªëng CSV chu·∫©n Scopus", data=csv, file_name="merged_scopus.csv", mime="text/csv")

    except Exception as e:
        st.error(f"‚ùå ƒê√£ x·∫£y ra l·ªói: {e}")
