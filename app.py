import streamlit as st
import pandas as pd
import difflib
from io import BytesIO
import bibtexparser

# ---------------------- X·ª≠ l√Ω d·ªØ li·ªáu ƒë·∫ßu v√†o ------------------------

def clean_title(title):
    if pd.isnull(title):
        return ""
    return ''.join(e for e in title.lower().strip() if e.isalnum() or e.isspace())

def convert_isi_bibtex_to_scopus(df):
    converted = pd.DataFrame()
    converted["Title"] = df.get("title", "")
    converted["Authors"] = df.get("author", "")
    converted["Source title"] = df.get("journal", "")
    converted["Year"] = df.get("year", "")
    converted["DOI"] = df.get("doi", "")
    converted["Author Keywords"] = df.get("keywords", "")
    converted["Affiliations"] = df.get("institution", df.get("note", ""))
    converted["References"] = ""
    return converted

def merge_datasets(df1, df2):
    df1["title_clean"] = df1["Title"].apply(clean_title)
    df2["title_clean"] = df2["Title"].apply(clean_title)

    merged = pd.merge(df1, df2, on="DOI", how="outer", suffixes=('_isi', '_scopus'))

    no_doi_isi = df1[df1["DOI"].isnull()]
    no_doi_scopus = df2[df2["DOI"].isnull()]
    for idx, row in no_doi_isi.iterrows():
        matches = difflib.get_close_matches(row["title_clean"], no_doi_scopus["title_clean"], n=1, cutoff=0.95)
        if matches:
            match_row = no_doi_scopus[no_doi_scopus["title_clean"] == matches[0]]
            if not match_row.empty:
                merged_row = pd.merge(row.to_frame().T, match_row, on="title_clean", how="inner")
                merged = pd.concat([merged, merged_row])

    merged.drop(columns=["title_clean"], inplace=True, errors="ignore")
    return merged

def convert_df_for_export(df):
    # ‚úÖ ∆Øu ti√™n Scopus, thay th·∫ø n·∫øu thi·∫øu b·∫±ng ISI
    df["Title"] = df.get("Title_scopus", "").fillna(df.get("Title_isi", ""))
    df["Authors"] = df.get("Authors_scopus", "").fillna(df.get("Authors_isi", ""))
    df["Source title"] = df.get("Source title_scopus", "").fillna(df.get("Source title_isi", ""))
    df["Year"] = df.get("Year_scopus", "").fillna(df.get("Year_isi", ""))
    df["DOI"] = df.get("DOI", "")
    df["Author Keywords"] = df.get("Author Keywords_scopus", "").fillna(df.get("Author Keywords_isi", ""))
    df["Affiliations"] = df.get("Affiliations_scopus", "").fillna(df.get("Affiliations_isi", ""))
    df["References"] = df.get("References_scopus", "").fillna(df.get("References_isi", ""))

    columns = ["Title", "Authors", "Source title", "Year", "DOI",
               "Author Keywords", "Affiliations", "References"]

    for col in columns:
        if col not in df.columns:
            df[col] = ""

    export_df = df[columns]
    buffer = BytesIO()
    export_df.to_csv(buffer, index=False)
    return buffer.getvalue()

# ---------------------- Giao di·ªán ng∆∞·ªùi d√πng ------------------------

st.set_page_config(page_title="Gh√©p d·ªØ li·ªáu ISI v√† Scopus", layout="wide")
st.title("üîó ·ª®ng d·ª•ng Gh√©p D·ªØ li·ªáu ISI & Scopus (chu·∫©n Scopus)")

file1 = st.file_uploader("üìÑ Ch·ªçn file ISI (.bib, .csv, .xlsx)", type=["bib", "csv", "xlsx"])
file2 = st.file_uploader("üìÑ Ch·ªçn file Scopus (.csv, .xlsx)", type=["csv", "xlsx"])

if file1 and file2:
    try:
        # X·ª≠ l√Ω file ISI
        ext1 = file1.name.split(".")[-1].lower()
        if ext1 == "bib":
            bib_data = bibtexparser.load(file1)
            isi_raw_df = pd.DataFrame(bib_data.entries)
            isi_df = convert_isi_bibtex_to_scopus(isi_raw_df)
        elif ext1 == "csv":
            isi_raw_df = pd.read_csv(file1)
            isi_df = convert_isi_bibtex_to_scopus(isi_raw_df)
        elif ext1 == "xlsx":
            isi_raw_df = pd.read_excel(file1)
            isi_df = convert_isi_bibtex_to_scopus(isi_raw_df)
        else:
            st.error("‚ùå ƒê·ªãnh d·∫°ng file ISI kh√¥ng h·ª£p l·ªá.")
            st.stop()

        # X·ª≠ l√Ω file Scopus
        ext2 = file2.name.split(".")[-1].lower()
        if ext2 == "csv":
            scopus_df = pd.read_csv(file2)
        elif ext2 == "xlsx":
            scopus_df = pd.read_excel(file2)
        else:
            st.error("‚ùå ƒê·ªãnh d·∫°ng file Scopus kh√¥ng h·ª£p l·ªá.")
            st.stop()

        scopus_df.columns = scopus_df.columns.str.strip()

        # C·∫£nh b√°o n·∫øu thi·∫øu d·ªØ li·ªáu
        required_columns = ["Title", "Authors", "DOI"]
        warnings = []

        for col in required_columns:
            if col not in isi_df.columns or isi_df[col].isnull().all():
                warnings.append(f"üìÅ ISI thi·∫øu ho·∫∑c tr·ªëng c·ªôt `{col}`")
            if col not in scopus_df.columns or scopus_df[col].isnull().all():
                warnings.append(f"üìÅ Scopus thi·∫øu ho·∫∑c tr·ªëng c·ªôt `{col}`")

        if warnings:
            st.warning("‚ö†Ô∏è C·∫£nh b√°o d·ªØ li·ªáu:")
            for w in warnings:
                st.markdown(f"- {w}")

        # Gh√©p d·ªØ li·ªáu
        with st.spinner("üîÑ ƒêang x·ª≠ l√Ω v√† gh√©p d·ªØ li·ªáu..."):
            merged_df = merge_datasets(isi_df, scopus_df)

        st.success("‚úÖ Gh√©p d·ªØ li·ªáu ho√†n t·∫•t!")
        st.dataframe(merged_df.head(50), use_container_width=True)

        # Ki·ªÉm tra ƒë·ªß s·ªë l∆∞·ª£ng t√°c gi·∫£ kh√°c nhau ch∆∞a
        unique_authors = merged_df["Authors_scopus"].fillna(merged_df["Authors_isi"]).dropna().unique()
        if len(unique_authors) < 3:
            st.error("‚ùå C·∫ßn √≠t nh·∫•t 3 t√°c gi·∫£ kh√°c nhau ƒë·ªÉ d√πng v·ªõi VOSviewer. Vui l√≤ng nh·∫≠p th√™m d·ªØ li·ªáu.")
        else:
            # T·∫£i xu·ªëng k·∫øt qu·∫£
            csv = convert_df_for_export(merged_df)
            st.download_button("üì• T·∫£i xu·ªëng file CSV (chu·∫©n Scopus)", data=csv, file_name="merged_scopus.csv", mime="text/csv")

    except Exception as e:
        st.error(f"‚ùå L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}")
